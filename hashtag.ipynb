{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81458ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Flatten, GlobalAveragePooling2D, Concatenate, Reshape\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aacd8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "images = []\n",
    "image_path = 'HARRISON_full/HARRISON/data_list.txt'\n",
    "with open(image_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        image_path = row[0]\n",
    "        images.append(image_path)\n",
    "prefix = \"D:/pkapu/Documents/Summer Internship/Listed/HARRISON_full/HARRISON/\"\n",
    "images = [prefix + item for item in images]\n",
    "images = images[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f51ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/pkapu/Documents/Summer Internship/Listed/HARRISON_full/HARRISON/instagram_dataset/sea/image_1284.jpg\n"
     ]
    }
   ],
   "source": [
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ef6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = []\n",
    "hash_path = 'HARRISON_full/HARRISON/tag_list.txt'\n",
    "with open(hash_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        hash_path = row[0].split()\n",
    "        hashtags.append(hash_path)\n",
    "hashtags = hashtags[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a559f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_data):\n",
    "    processed_images = []\n",
    "    if isinstance(image_data, list):\n",
    "        for image_path in image_data:\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "                img = img / 255.0\n",
    "                processed_images.append(img)\n",
    "            else:\n",
    "                print(f\"Error loading image: {image_path}\")\n",
    "    else:\n",
    "        img = cv2.imread(image_data)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = img / 255.0\n",
    "            processed_images.append(img)\n",
    "        else:\n",
    "            print(f\"Error loading image: {image_data}\")\n",
    "    return np.array(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae21f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hashtags(hashtags):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(hashtags)\n",
    "    sequences = tokenizer.texts_to_sequences(hashtags)\n",
    "    word_index = tokenizer.word_index\n",
    "    return sequences, word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffeaa687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, max_sequence_length):\n",
    "    # Image encoder\n",
    "    image_input = Input(shape=(224, 224, 3))  # Adjust input shape as per your model's input size\n",
    "    image_model = VGG16(weights='imagenet', include_top=False)(image_input)\n",
    "    image_features = Flatten()(image_model)\n",
    "\n",
    "    # Hashtag generator\n",
    "    hashtag_input = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(vocab_size, 256, input_length=max_sequence_length)(hashtag_input)\n",
    "    lstm = LSTM(256)(embedding_layer)\n",
    "    output = Dense(vocab_size, activation='softmax')(lstm)\n",
    "\n",
    "    model = Model(inputs=[image_input, hashtag_input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517ffca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def prepare_data(images, hashtags, word_index, max_sequence_length):\n",
    "    start_token = '<start>'\n",
    "    if start_token not in word_index:\n",
    "        word_index[start_token] = len(word_index) + 1\n",
    "    X_image = []  # List to store image data\n",
    "    X_hashtag = []  # List to store hashtag data\n",
    "    y = []  # List to store target labels\n",
    "\n",
    "    for image, hashtag_list in zip(images, hashtags):\n",
    "        # Process image data (e.g., using preprocess_image() function)\n",
    "        image_data = preprocess_image(image)\n",
    "        X_image.append(image_data)\n",
    "\n",
    "        # Process hashtag data (convert words to indices)\n",
    "        hashtag_indices = [word_index.get(word, 0) for word in hashtag_list]  # Use 0 for unknown words\n",
    "        X_hashtag.append(hashtag_indices)\n",
    "\n",
    "        # Prepare target labels (one-hot encoding or other suitable encoding)\n",
    "        target = [0] * vocab_size  # Initialize with all zeros\n",
    "        for index in hashtag_indices:\n",
    "            target[index] = 1\n",
    "        y.append(target)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X_image = np.array(X_image)\n",
    "    X_hashtag = pad_sequences(X_hashtag, maxlen=max_sequence_length)\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X_image, X_hashtag, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b8db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_image, X_hashtag, y):\n",
    "    loss, accuracy = model.evaluate([X_image, X_hashtag], y)\n",
    "    print(\"Loss: {:.4f}\".format(loss))\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bcea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hashtags(model, image_path, word_index, max_sequence_length, num_hashtags=10):\n",
    "    image = preprocess_image(image_path)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    sequence_input = np.zeros((1, max_sequence_length))\n",
    "    sequence_input[0, 0] = word_index['<start>']  # Start token\n",
    "\n",
    "    for i in range(1, max_sequence_length):\n",
    "        predictions = model.predict([image, sequence_input])\n",
    "        predicted_word_index = np.argmax(predictions[0, i-1])\n",
    "        sequence_input[0, i] = predicted_word_index\n",
    "\n",
    "    predicted_hashtags = []\n",
    "    for index in sequence_input[0]:\n",
    "        if index == 0:  # End token\n",
    "            break\n",
    "        word = list(word_index.keys())[list(word_index.values()).index(index)]\n",
    "        predicted_hashtags.append(word)\n",
    "\n",
    "    return predicted_hashtags[:num_hashtags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, word_index = preprocess_hashtags(hashtags)\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f5438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 2s 8ms/step - loss: 1.1549 - accuracy: 0.9370\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 9.8208e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 4.9760e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 2.9827e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.9743e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.3840e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0076e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m test_image_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(test_image_data, padded_test_hashtag\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make predictions using the model\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_image_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_test_hashtag\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Retrieve top 10 predicted hashtags\u001b[39;00m\n\u001b[0;32m     50\u001b[0m top_10_hashtags \u001b[38;5;241m=\u001b[39m [hashtag \u001b[38;5;28;01mfor\u001b[39;00m _, hashtag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m], word_index\u001b[38;5;241m.\u001b[39mkeys()), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:\u001b[38;5;241m10\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2278\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2274\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(\n\u001b[0;32m   2275\u001b[0m                     end_step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs}\n\u001b[0;32m   2276\u001b[0m                 )\n\u001b[0;32m   2277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2281\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2282\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2284\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m         )\n\u001b[0;32m   2286\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m   2287\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2288\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[0;32m   2289\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "sequences, word_index = preprocess_hashtags(hashtags)\n",
    "X_image = preprocess_image(images)\n",
    "max_sequence_length = 20  # Maximum sequence length for hashtags\n",
    "vocab_size = len(word_index) + 1\n",
    "X_image, X_hashtag, y = prepare_data(images, hashtags, word_index, max_sequence_length)\n",
    "X_image = np.squeeze(X_image, axis=1)\n",
    "num_classes = 10  # Number of classes\n",
    "y_encoded = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "# Define your model architecture\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "hashtag_input = Input(shape=(max_sequence_length,))\n",
    "flattened_hashtags = Embedding(input_dim=len(word_index) + 1, output_dim=100, input_length=max_sequence_length)(hashtag_input)\n",
    "flattened_hashtags = Reshape((max_sequence_length, 100, 1))(flattened_hashtags)\n",
    "flattened_hashtags = GlobalAveragePooling2D()(flattened_hashtags)\n",
    "flattened_image = GlobalAveragePooling2D()(image_input)\n",
    "concatenated_inputs = Concatenate(axis=-1)([flattened_image, flattened_hashtags])\n",
    "dense_layer = Dense(256, activation='relu')(concatenated_inputs)\n",
    "output_layer = Dense(num_classes, activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=[image_input, hashtag_input], outputs=output_layer)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit([X_image, X_hashtag], y_encoded[:, 0, :], epochs=10, batch_size=32)\n",
    "# Perform inference\n",
    "test_image = images[2001:2500]  # Test image data\n",
    "test_hashtag = hashtags[2001:2500]  # Test hashtag sequence\n",
    "# Preprocess the test image\n",
    "test_image_data = preprocess_image(test_image)  # Assuming test_image_path is the path to your test image\n",
    "\n",
    "# Ensure test_image_data has the correct shape\n",
    "test_image_data = test_image_data.reshape((-1, 224, 224, 3))\n",
    "\n",
    "# Generate padded test hashtag sequence\n",
    "test_hashtag_sequence = [\"<start> \" + hashtag + \" <end>\" for hashtag in test_hashtag]\n",
    "test_hashtag_sequence = tokenizer.texts_to_sequences(test_hashtag_sequence)\n",
    "padded_test_hashtag = pad_sequences(test_hashtag_sequence, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Repeat the test image data to match the number of samples in padded_test_hashtag\n",
    "test_image_data = np.repeat(test_image_data, padded_test_hashtag.shape[0], axis=0)\n",
    "\n",
    "# Make predictions using the model\n",
    "predictions = model.predict([test_image_data, padded_test_hashtag])\n",
    "\n",
    "\n",
    "\n",
    "# Retrieve top 10 predicted hashtags\n",
    "top_10_hashtags = [hashtag for _, hashtag in sorted(zip(predictions[0], word_index.keys()), reverse=True)[:10]]\n",
    "print(top_10_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1855c2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/pkapu/Documents/Summer Internship/Listed/HARRISON_full/HARRISON/instagram_dataset/sea/image_1284.jpg\n"
     ]
    }
   ],
   "source": [
    "print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1c91b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 85ms/step - loss: 29.6407 - accuracy: 0.9000 - val_loss: 30.5022 - val_accuracy: 0.9700\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 36.7097 - accuracy: 0.9825 - val_loss: 38.4855 - val_accuracy: 0.9700\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 37.0907 - accuracy: 0.9825 - val_loss: 39.3527 - val_accuracy: 0.9700\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 39.0847 - accuracy: 0.9825 - val_loss: 44.1943 - val_accuracy: 0.9700\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 43.2756 - accuracy: 0.9825 - val_loss: 48.8827 - val_accuracy: 0.9700\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 46.9097 - accuracy: 0.9825 - val_loss: 52.7451 - val_accuracy: 0.9700\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 50.1517 - accuracy: 0.9825 - val_loss: 56.9113 - val_accuracy: 0.9700\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 53.9390 - accuracy: 0.9825 - val_loss: 61.4508 - val_accuracy: 0.9700\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 57.8623 - accuracy: 0.9825 - val_loss: 65.7921 - val_accuracy: 0.9700\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 61.4173 - accuracy: 0.9825 - val_loss: 70.0135 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cff5867b80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences, word_index = preprocess_hashtags(hashtags)\n",
    "\n",
    "vocab_size = len(word_index) + 1  # Add 1 for the padding token\n",
    "max_sequence_length = 10  # Adjust as per your dataset\n",
    "\n",
    "# Step 4: Training\n",
    "X_image, X_hashtag, y = prepare_data(images, hashtags, word_index, max_sequence_length)\n",
    "model = build_model(vocab_size, max_sequence_length)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit([X_image, X_hashtag], y, batch_size=32, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "365dab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 64.5801 - accuracy: 0.9800\n",
      "Loss: 64.5801\n",
      "Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_image, X_hashtag, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d85c3313",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\pkapu\\AppData\\Local\\Temp\\ipykernel_13952\\4185427609.py\", line 2, in <module>\n      predicted_hashtags = predict_hashtags(model, new_image_path, word_index, max_sequence_length)\n    File \"C:\\Users\\pkapu\\AppData\\Local\\Temp\\ipykernel_13952\\1075312121.py\", line 9, in predict_hashtags\n      predictions = model.predict([image, sequence_input])\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_1/embedding_lookup'\nindices[0,0] = 436 is not in [0, 436)\n\t [[{{node model_1/embedding_1/embedding_lookup}}]] [Op:__inference_predict_function_10546]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/pkapu/Documents/Summer Internship/Listed/HARRISON_full/HARRISON/instagram_dataset/sea/image_1315.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted_hashtags \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_hashtags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sequence_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Hashtags:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_hashtags)\n",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m, in \u001b[0;36mpredict_hashtags\u001b[1;34m(model, image_path, word_index, max_sequence_length, num_hashtags)\u001b[0m\n\u001b[0;32m      6\u001b[0m sequence_input[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m word_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<start>\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Start token\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_sequence_length):\n\u001b[1;32m----> 9\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     predicted_word_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m, i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     11\u001b[0m     sequence_input[\u001b[38;5;241m0\u001b[39m, i] \u001b[38;5;241m=\u001b[39m predicted_word_index\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\pkapu\\AppData\\Local\\Temp\\ipykernel_13952\\4185427609.py\", line 2, in <module>\n      predicted_hashtags = predict_hashtags(model, new_image_path, word_index, max_sequence_length)\n    File \"C:\\Users\\pkapu\\AppData\\Local\\Temp\\ipykernel_13952\\1075312121.py\", line 9, in predict_hashtags\n      predictions = model.predict([image, sequence_input])\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2253, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\pkapu\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_1/embedding_1/embedding_lookup'\nindices[0,0] = 436 is not in [0, 436)\n\t [[{{node model_1/embedding_1/embedding_lookup}}]] [Op:__inference_predict_function_10546]"
     ]
    }
   ],
   "source": [
    "new_image_path = 'D:/pkapu/Documents/Summer Internship/Listed/HARRISON_full/HARRISON/instagram_dataset/sea/image_1315.jpg'  # Replace with your image path\n",
    "predicted_hashtags = predict_hashtags(model, new_image_path, word_index, max_sequence_length)\n",
    "print(\"Predicted Hashtags:\", predicted_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68963912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
